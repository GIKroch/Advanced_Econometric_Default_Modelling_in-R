n<-length(m$y)
k<-max(table(m$y))
correct<-table(m$y==round(m$fitted.values))[["TRUE"]]
(correct-k)/(n-k)
}
adj.countR2(myprobit_final)
library(DescTools)
PseudoR2(myprobit_final, which = "Nagelkerke")
PseudoR2(myprobit_final, which = "McKelveyZavoina")
# The code was taken from:
#://stats.stackexchange.com/questions/160709/how-do-you-get-count-r2-in-r-with-missing-data
countR2<-function(m) mean(m$y==round(m$fitted.values))
countR2(myprobit_final)
# The code was taken from:
#://stats.stackexchange.com/questions/160709/how-do-you-get-count-r2-in-r-with-missing-data
adj.countR2<-function(m) {
n<-length(m$y)
k<-max(table(m$y))
correct<-table(m$y==round(m$fitted.values))[["TRUE"]]
(correct-k)/(n-k)
}
adj.countR2(myprobit_final)
# The code was taken from:
#://stats.stackexchange.com/questions/160709/how-do-you-get-count-r2-in-r-with-missing-data
countR2<-function(m) mean(m$y==round(m$fitted.values))
as.numeric(countR2(myprobit_final))
x <- summary(myprobit_final)
PseudoR2(myprobit_final,which = "Nagelkerke")
PseudoR2(mylogit_final, which = )
PseudoR2(mylogit_final, which = "McKelvey-Zavoina")
PseudoR2(mylogit_final, which = "McKelveyZavoina")
PseudoR2(mylogit_final)
knitr::opts_chunk$set(echo = TRUE)
library(foreign)
library(kableExtra) # Nice tables
library(mice) # Multivariate Imputation
library(reshape) # Melt
library(ggplot2) # Charts
library(stargazer) # very nice tables
library(sandwich) # vcovHC
library(lmtest) #coeftest
library(mfx) #probitmfx
library(DescTools) #PseudoR2
options(knitr.table.format = "latex")
PseudoR2(myprobit_final)
setwd("C:/Users/user/Desktop/studia/Data Science/Semestr 2/Advanced_Econometrics/projekt/Advanced_Econometric_Default_Modelling_in-R")
data <- read.csv2("imputedData.csv")
missing_d <- data[rowSums(is.na(data))>0,]
sum(missing_d$class)
data <- data[rowSums(is.na(data))==0,]
View(data)
coln <- as.character(read.csv2("column_names.csv", header = FALSE)$V2)
View(data)
coln <- c(coln, "class")
colnames(data) <- coln
View(data)
library(ggcorrplot)
library(caret)
library(logistf)
library(dplyr)
data1 <- data
selected_names <- c()
selected_names <- lapply(names(X_3),function(name){
one_cov <- glm(y_3 ~ X_3[,name], family=binomial(link= "logit"))
if (as.numeric(summary(one_cov)$coefficients[,4][2]) < 0.25){
print(summary(one_cov)$coefficients[,4][2])
selected_names <- c(selected_names, name)
}
})
y_3 <- data$class
X_3 <- data
selected_names <- c()
selected_names <- lapply(names(X_3),function(name){
one_cov <- glm(y_3 ~ X_3[,name], family=binomial(link= "logit"))
if (as.numeric(summary(one_cov)$coefficients[,4][2]) < 0.25){
print(summary(one_cov)$coefficients[,4][2])
selected_names <- c(selected_names, name)
}
})
selected_names <- unlist(selected_names)
selected_names <- unlist(selected_names)
selected_names
data1 %>% select(selected_names)
data1 <- data1 %>% select(selected_names)
data1 <- data
selected_names <- c()
selected_names <- lapply(names(X_3),function(name){
one_cov <- glm(y_3 ~ X_3[,name], family=binomial(link= "probit"))
if (as.numeric(summary(one_cov)$coefficients[,4][2]) < 0.25){
print(summary(one_cov)$coefficients[,4][2])
selected_names <- c(selected_names, name)
}
})
selected_names <- unlist(selected_names)
selected_names
data1 <- data1 %>% select(selected_names)
## However after running the code it occured that with such an approach every variable seems to be significant
## The another approach to limit number of variables is to drop those which are highly correlated.
## After the analysis of correlation data following columns were removed
corr <- round(cor(X_3), 1)
to_drop <- findCorrelation(corr, cutoff = 0.9, verbose = FALSE, names = F,
exact = ncol(corr) < 100)
to_drop
data1 <- data1[,-to_drop]
# Fit the full model
full.model <- glm(formula = class ~.,data = data1, family=binomial(link= "probit"), control = list(maxit = 100))
View(data1)
data <- read.csv2("imputedData.csv")
missing_d <- data[rowSums(is.na(data))>0,]
sum(missing_d$class)
data <- data[rowSums(is.na(data))==0,]
data1 <- data
selected_names <- c()
selected_names <- lapply(names(X_3),function(name){
one_cov <- glm(y_3 ~ X_3[,name], family=binomial(link= "probit"))
if (as.numeric(summary(one_cov)$coefficients[,4][2]) < 0.25){
print(summary(one_cov)$coefficients[,4][2])
selected_names <- c(selected_names, name)
}
})
selected_names <- unlist(selected_names)
selected_names
data1 <- data1 %>% select(selected_names)
y_3 <- data$class
X_3 <- data
selected_names <- c()
selected_names <- lapply(names(X_3),function(name){
one_cov <- glm(y_3 ~ X_3[,name], family=binomial(link= "probit"))
if (as.numeric(summary(one_cov)$coefficients[,4][2]) < 0.25){
selected_names <- c(selected_names, name)
}
})
selected_names <- unlist(selected_names)
data1 <- data1 %>% select(selected_names)
## The another approach to limit number of variables is to drop those which are highly correlated.
## After the analysis of correlation data we removed next 15 variables
corr <- round(cor(X_3), 1)
to_drop <- findCorrelation(corr, cutoff = 0.9, verbose = FALSE, names = F,
exact = ncol(corr) < 100)
data1 <- data1[,-to_drop]
## Now we have 33 dependent variables. It is still a lot. Our next step will be to run stepwise regression in order to limit number of
## features
library(MASS)
# Fit the full model
full.model <- glm(formula = class ~.,data = data1, family=binomial(link= "probit"), control = list(maxit = 100))
# Fit the full model
full.model <- glm(class ~.,data = data1, family=binomial(link= "probit"), control = list(maxit = 100))
# Fit the full model
full.model <- glm(class ~.,data = as.matrix(data1), family=binomial(link= "probit"), control = list(maxit = 100))
View(data1)
data1$class <- y_3
View(data1)
# Fit the full model
full.model <- glm(class ~.,data = data1, family=binomial(link= "probit"), control = list(maxit = 100))
# Fit the full model
full.model <- glm(class ~.,data = data1, family=binomial(link= "probit"), control = list(maxit = 200))
# Stepwise regression model
step.model <- stepAIC(full.model, direction = "both",
trace = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(foreign)
library(kableExtra) # Nice tables
library(mice) # Multivariate Imputation
library(reshape) # Melt
library(ggplot2) # Charts
library(stargazer) # very nice tables
library(sandwich) # vcovHC
library(lmtest) #coeftest
library(mfx) #probitmfx
library(DescTools) #PseudoR2
library(ResourceSelection) #gof
install.packages("ResourceSolution")
knitr::opts_chunk$set(echo = TRUE)
library(foreign)
library(kableExtra) # Nice tables
library(mice) # Multivariate Imputation
library(reshape) # Melt
library(ggplot2) # Charts
library(stargazer) # very nice tables
library(sandwich) # vcovHC
library(lmtest) #coeftest
library(mfx) #probitmfx
library(DescTools) #PseudoR2
# library(ResourceSelection) #gof
options(knitr.table.format = "latex")
data <- read.csv2("imputedData.csv")
missing_d <- data[rowSums(is.na(data))>0,]
#sum(missing_d$class)
data <- data[rowSums(is.na(data))==0,]
SIZE <- data$Attr29
TLTA <- data$Attr2
WCTA <- data$Attr3
OENEG <- ifelse(TLTA>=1, 1, 0)
NITA <- data$Attr1
INONE <- ifelse(NITA>0, 1, 0)
CHSALES <- data$Attr21
FUTL <- data$Attr16
BANKRUPTCY <- data$class
ohl_data <- data.frame(SIZE, TLTA, WCTA, OENEG, NITA, INONE, FUTL, CHSALES, BANKRUPTCY)
ohl_data$SIZE2 <- ohl_data$SIZE^2
myprobit_final <- glm(BANKRUPTCY~SIZE+TLTA+WCTA+NITA+INONE+FUTL+SIZE2+CHSALES, data=ohl_data, family=binomial(link="probit"))
# After running the stepwise regression we ended up with the model which uses 27 dependent variables from which 21 are significant
model_summary <- summary(step.model)
model_summary
data <- read.csv2("imputedData.csv")
missing_d <- data[rowSums(is.na(data))>0,]
sum(missing_d$class)
data <- data[rowSums(is.na(data))==0,]
coln <- as.character(read.csv2("column_names.csv", header = FALSE)$V2)
coln <- c(coln, "class")
colnames(data) <- coln
y_3 <- data$class
data$class <- NULL
X_3 <- data
data1 <- data
selected_names <- c()
selected_names <- lapply(names(X_3),function(name){
one_cov <- glm(y_3 ~ X_3[,name], family=binomial(link= "probit"))
if (as.numeric(summary(one_cov)$coefficients[,4][2]) < 0.25){
selected_names <- c(selected_names, name)
}
})
selected_names <- unlist(selected_names)
selected_names
data1 <- data1 %>% select(selected_names)
selected_names
data1 <- data1 %>% select(selected_names)
selected_names
data1
data1 <- data1 %>% select(selected_names)
data1 <- data1 %>% select(c = selected_names)
selected_names
library(dplyr)
data1 <- data1 %>% select(c = selected_names)
data1 <- data1 %>% dplyr::select(c = selected_names)
data1
data1 <- data1 %>% dplyr::select(selected_names)
data <- read.csv2("imputedData.csv")
missing_d <- data[rowSums(is.na(data))>0,]
sum(missing_d$class)
data <- data[rowSums(is.na(data))==0,]
coln <- as.character(read.csv2("column_names.csv", header = FALSE)$V2)
coln <- c(coln, "class")
colnames(data) <- coln
y_3 <- data$class
data$class <- NULL
X_3 <- data
data1 <- data
selected_names <- c()
selected_names <- lapply(names(X_3),function(name){
one_cov <- glm(y_3 ~ X_3[,name], family=binomial(link= "probit"))
if (as.numeric(summary(one_cov)$coefficients[,4][2]) < 0.25){
selected_names <- c(selected_names, name)
}
})
selected_names <- unlist(selected_names)
selected_names
data1 <- data1 %>% dplyr::select(selected_names)
data1
## The another approach to limit number of variables is to drop those which are highly correlated.
## After the analysis of correlation data we removed next 15 variables
corr <- round(cor(X_3), 1)
to_drop <- findCorrelation(corr, cutoff = 0.9, verbose = FALSE, names = F,
exact = ncol(corr) < 100)
data1 <- data1[,-to_drop]
data1$class <- y_3
## Now we have 33 dependent variables. It is still a lot. Our next step will be to run stepwise regression in order to limit number of
## features
library(MASS)
# Fit the full model
full.model <- glm(class ~.,data = data1, family=binomial(link= "probit"), control = list(maxit = 200))
# Fit the full model
full.model <- glm(class ~.,data = data1, family=binomial(link= "probit"), control = list(maxit = 50))
# Stepwise regression model
step.model <- stepAIC(full.model, direction = "both",
trace = FALSE)
# After running the stepwise regression we ended up with the model which uses 27 dependent variables from which 21 are significant
model_summary <- summary(step.model)
model_summary
lrtest(step.model, myprobit_final)
lrtest(myprobit_final, step.model)
lrtest(step.model, myprobit_final)
lrtest(myprobit_final, step.model)
myprobit2 <- glm(BANKRUPTCY~SIZE+TLTA+WCTA+OENEG+NITA+FUTL+SIZE2+CHSALES+CHSALES:INONE,
data=ohl_data, family=binomial(link="probit"))
lrtest(myprobit2, myprobit_final)
lrtest(myprobit_final, myprobit2)
lrtest(myprobit_final, step.model)
data1 %>% rename(BANKRUPTCY = SEX)
data1 %>% dplry::rename(BANKRUPTCY = SEX)
data1 %>% dplyr::rename(BANKRUPTCY = SEX)
data1 %>% dplyr::rename(SEX = BANKRUPTCY )
data1 %>% dplyr::rename("SEX" = BANKRUPTCY )
data1 %>% dplyr::rename(BANKRUPTCY = "SEX")
rename(data1, SEX = BANKRUPTCY)
dplyr::rename(data1, SEX = BANKRUPTCY)
dplyr::rename(data1, "SEX" = BANKRUPTCY)
dplyr::rename_(data1, "SEX" = BANKRUPTCY)
lrtest(myprobit_final, step.model)
data <- read.csv2("imputedData.csv")
missing_d <- data[rowSums(is.na(data))>0,]
sum(missing_d$class)
data <- data[rowSums(is.na(data))==0,]
coln <- as.character(read.csv2("column_names_1.csv", header = FALSE)$V2)
coln <- c(coln, "BANKRUPTCY")
colnames(data) <- coln
y_3 <- data$BANKRUPTCY
data$BANKRUPTCY <- NULL
X_3 <- data
data1 <- data
View(data1)
data1$INONE <- ifelse(NITA>0, 1, 0)
data1$OENEG <- ifelse(TLTA>=1, 1, 0)
data1 <- read.csv2("imputedData.csv")
missing_d <- data1[rowSums(is.na(data))>0,]
data1 <- read.csv2("imputedData.csv")
missing_d <- data1[rowSums(is.na(data1))>0,]
sum(missing_d$class)
data1 <- data[rowSums(is.na(data))==0,]
data1 <- read.csv2("imputedData.csv")
missing_d <- data1[rowSums(is.na(data1))>0,]
sum(missing_d$class)
data1 <- data[rowSums(is.na(data1))==0,]
coln <- as.character(read.csv2("column_names_1.csv", header = FALSE)$V2)
coln <- c(coln, "BANKRUPTCY")
colnames(data1) <- coln
coln <- c(coln, "BANKRUPTCY")
colnames(data1) <- coln
data1 <- read.csv2("imputedData.csv")
missing_d <- data1[rowSums(is.na(data1))>0,]
sum(missing_d$class)
data1 <- data[rowSums(is.na(data1))==0,]
coln <- as.character(read.csv2("column_names_1.csv", header = FALSE)$V2)
View(data1)
data1 <- read.csv2("imputedData.csv")
missing_d <- data1[rowSums(is.na(data1))>0,]
sum(missing_d$class)
data1 <- data[rowSums(is.na(data1))==0,]
View(data1)
data1 <- read.csv2("imputedData.csv")
missing_d <- data1[rowSums(is.na(data1))>0,]
sum(missing_d$class)
data1 <- data1[rowSums(is.na(data1))==0,]
coln <- as.character(read.csv2("column_names_1.csv", header = FALSE)$V2)
coln <- c(coln, "BANKRUPTCY")
colnames(data1) <- coln
data1$INONE <- ifelse(NITA>0, 1, 0)
data1$OENEG <- ifelse(TLTA>=1, 1, 0)
y_3 <- data1$BANKRUPTCY
data1$BANKRUPTCY <- NULL
X_3 <- data1
selected_names <- c()
selected_names <- lapply(names(X_3),function(name){
one_cov <- glm(y_3 ~ X_3[,name], family=binomial(link= "probit"))
if (as.numeric(summary(one_cov)$coefficients[,4][2]) < 0.25){
selected_names <- c(selected_names, name)
}
})
selected_names <- unlist(selected_names)
selected_names
data1 <- data1 %>% dplyr::select(selected_names)
## The another approach to limit number of variables is to drop those which are highly correlated.
## After the analysis of correlation data we removed next 15 variables
corr <- round(cor(X_3), 1)
to_drop <- findCorrelation(corr, cutoff = 0.9, verbose = FALSE, names = F,
exact = ncol(corr) < 100)
data1 <- data1[,-to_drop]
data1$BANKRUPTCY <- y_3
View(data1)
# Fit the full model
full.model <- glm(BANKRUPTCY ~.,data = data1, family=binomial(link= "probit"), control = list(maxit = 50))
# Stepwise regression model
step.model <- stepAIC(full.model, direction = "both",
trace = FALSE)
# After running the stepwise regression we ended up with the model which uses 27 dependent variables from which 21 are significant
model_summary <- summary(step.model)
model_summary
lrtest(myprobit_final, step.model)
lrtest(step.model,myprobit_final)
# ------------------------------------------------------------
# Exercise 3
# ------------------------------------------------------------
setwd("C:/Users/user/Desktop/studia/Data Science/Semestr 2/Advanced_Econometrics/ćwiczenia/AE_Lab_08")
vote2 = read.csv(file = "vote2.csv", header=TRUE, sep=";", dec = ",")
View(vote2)
vote2$income2 = vote2$income^2
vote2$region3 = 0
vote2$region3[vote2$region==2] = 1
# ii. Use R to calculate the marginal effect numerically.
dem.probit = glm(dem~income+income2+region3, data=vote2, family=binomial(link="probit"))
user.def.obs = c(1,34,34^2,0) #convention: (intercept, x1, x2, ...)
meff = as.vector(dnorm(user.def.obs%*%dem.probit$coefficients))*dem.probit$coefficients
# iv. Test the hypothesis H0: beta1=beta2=0 using the Wald statistics
h <- rbind(c(0,1,0,0), c(0,0,1,0))
# h %*% coef(dem.probit)
wald.test.results = wald.test(b = coef(dem.probit), Sigma = vcov(dem.probit), L = h)
library("aod")
install.packages("aod")
library("aod")
# h %*% coef(dem.probit)
wald.test.results = wald.test(b = coef(dem.probit), Sigma = vcov(dem.probit), L = h)
wald.test.results
# v. Test the hypothesis H0: beta1=beta2=0 using the likelihhod ratio test
dem.U = glm(dem~income+income2+region3, data=vote2, family=binomial(link="probit"))
dem.R = glm(dem~region3, data=vote2, family=binomial(link="probit"))
lrtest(dem.U, dem.R)
lrtest(dem.R, dem.U)
myprobit2 <- glm(BANKRUPTCY~SIZE+TLTA+WCTA+OENEG+NITA+FUTL+SIZE2+CHSALES+CHSALES:INONE,
data=ohl_data, family=binomial(link="probit"))
lrtest(myprobit2, myprobit_final)
myprobit3 <- glm(BANKRUPTCY~SIZE+TLTA+WCTA+OENEG+INONE+FUTL+SIZE2+CHSALES+CHSALES:NITA,
data=ohl_data, family=binomial(link="probit"))
lrtest(myprobit3, myprobit_final)
myprobit3 <- glm(BANKRUPTCY~SIZE+TLTA+WCTA+OENEG+NITA+FUTL+SIZE2+CHSALES+NITA:INONE,
data=ohl_data, family=binomial(link="probit"))
lrtest(myprobit3, myprobit_final)
myprobit3 <- glm(BANKRUPTCY~SIZE+TLTA+WCTA+OENEG+NITA+FUTL+SIZE2+CHSALES+NITA:INONE,
data=ohl_data, family=binomial(link="probit"))
lrtest(myprobit3, myprobit_final)
lrtest(dem.U, dem.R)
# v. Test the hypothesis H0: beta1=beta2=0 using the likelihhod ratio test
dem.U = glm(dem~income+income2+region3, data=vote2, family=binomial(link="probit"))
lrtest(dem.U, dem.R)
dem.R = glm(dem~region3, data=vote2, family=binomial(link="probit"))
anova(dem.R, dem.U)
anova.gpcm(dem.R, dem.U)
anova.gpcm(dem.R, dem, test="LRT")
anova(dem.R, dem, test="LRT")
anova(dem.R, dem.U, test="LRT")
lrtest(dem.U, dem.R)
myprobit2 <- glm(BANKRUPTCY~SIZE+TLTA+WCTA+OENEG+NITA+FUTL+SIZE2+CHSALES+CHSALES:INONE,
data=ohl_data, family=binomial(link="probit"))
lrtest(myprobit2, myprobit_final)
anova(myprobit_final, myprobit2, test = "LRT")
anova(myprobit2, myprobit_final,test = "LRT")
anova(myprobit_final, step.model)
anova(myprobit_final, step.model, test= "LRT")
lrtest(step.model,myprobit_final)
lrtest(myprobit_final, step.model)
anova(myprobit_final, step.model, test= "LRT")
lrtest(myprobit2, myprobit_final)
lrtest(myprobit_final, step.model)
lrtest(step.model, myprobit_final)
lrtest(myprobit2, myprobit_final)
length(selected_names)
selected_names <- c()
selected_names <- lapply(names(X_3),function(name){
one_cov <- glm(y_3 ~ X_3[,name], family=binomial(link= "probit"))
if (as.numeric(summary(one_cov)$coefficients[,4][2]) < 0.25){
selected_names <- c(selected_names, name)
}
})
selected_names <- unlist(selected_names)
length(selected_names)
setwd("C:/Users/user/Desktop/studia/Data Science/Semestr 2/Advanced_Econometrics/projekt/Advanced_Econometric_Default_Modelling_in-R")
data1 <- read.csv2("imputedData.csv")
missing_d <- data1[rowSums(is.na(data1))>0,]
sum(missing_d$class)
data1 <- data1[rowSums(is.na(data1))==0,]
coln <- as.character(read.csv2("column_names_1.csv", header = FALSE)$V2)
coln <- c(coln, "BANKRUPTCY")
colnames(data1) <- coln
data1$INONE <- ifelse(NITA>0, 1, 0)
data1$OENEG <- ifelse(TLTA>=1, 1, 0)
y_3 <- data1$BANKRUPTCY
data1$BANKRUPTCY <- NULL
X_3 <- data1
selected_names <- c()
selected_names <- lapply(names(X_3),function(name){
one_cov <- glm(y_3 ~ X_3[,name], family=binomial(link= "probit"))
if (as.numeric(summary(one_cov)$coefficients[,4][2]) < 0.25){
selected_names <- c(selected_names, name)
}
})
selected_names <- unlist(selected_names)
length(selected_names)
data1 <- data1 %>% dplyr::select(selected_names)
selected_names
## The another approach to limit number of variables is to drop those which are highly correlated.
## After the analysis of correlation data we removed next 15 variables
corr <- round(cor(X_3), 1)
to_drop <- findCorrelation(corr, cutoff = 0.9, verbose = FALSE, names = F,
exact = ncol(corr) < 100)
data1 <- data1[,-to_drop]
data1$BANKRUPTCY <- y_3
install.packages(ResourceSelection)
install.packages("ResourceSelection")
summary(step.model)
saveRDS(step.model, "step_model.RDS")
xx <- readRDS("step_model.RDS")
summary(xx)
kableExtra::kable(step.model)
stargazer(step.model)
step.model$coefficients
broom::tidy(step.model$coefficients)
sum <- summary(step.model)
sum
broom::tidy(sum)
sum$coefficients
broom::tidy(sum$coefficients)
mm <- broom::tidy(sum$coefficients)
View(mm)
step.model$formula
step.model$coefficients
length(step.model$coefficients)
mm
kableExtra::kable(mm)
xd <- anova(myprobit_final, step.model, test= "LRT")
xd
xd$`Resid. Dev`
broom::tidy(xd)
as.data.frame(xd)
